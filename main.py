#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Linux.do è‡ªåŠ¨åŒ–æµè§ˆå·¥å…· - é‡æ„ç‰ˆ v6.0
====================================
é‡æ„å†…å®¹ï¼š
1. âœ… å€Ÿé‰´å‚è€ƒä»£ç çš„100%æµè§ˆç—•è¿¹æ”¶é›†æœºåˆ¶
2. âœ… é›†æˆlocalStorageæ ‡è®°ç³»ç»Ÿ
3. âœ… ä¼˜åŒ–é¡µé¢åŠ è½½å’Œäº‹ä»¶è§¦å‘æ—¶æœº
4. âœ… ä¿æŒæ‰€æœ‰åæ£€æµ‹åŠŸèƒ½
"""

import os
import random
import time
import sys
import json
import re
import base64
import requests
from datetime import datetime
from loguru import logger
from DrissionPage import ChromiumPage, ChromiumOptions
from tabulate import tabulate

# æ—¥å¿—é…ç½® - åªä¿ç•™INFOåŠä»¥ä¸Šçº§åˆ«
logger.remove()
logger.add(sys.stderr, level="INFO", format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>")

# ======================== é…ç½®å¸¸é‡ ========================
SITE_CREDENTIALS = {
    'linux_do': {
        'username': os.getenv('LINUXDO_USERNAME'),
        'password': os.getenv('LINUXDO_PASSWORD')
    },
    'idcflare': {
        'username': os.getenv('IDCFLARE_USERNAME'),
        'password': os.getenv('IDCFLARE_PASSWORD')
    }
}

SITES = [
    {
        'name': 'linux_do',
        'base_url': 'https://linux.do',
        'login_url': 'https://linux.do/login',
        'private_topic_url': 'https://linux.do/t/topic/870130',
        'unread_url': 'https://linux.do/unread',
        'connect_url': 'https://connect.linux.do',
        'user_url': 'https://linux.do/u',
        'cf_cookies_file': "cf_cookies_linux_do.json",
        'session_file': "session_data_linux_do.json"
    },
    {
        'name': 'idcflare',
        'base_url': 'https://idcflare.com',
        'login_url': 'https://idcflare.com/login',
        'private_topic_url': 'https://idcflare.com/t/topic/24',
        'unread_url': 'https://idcflare.com/unread',
        'connect_url': 'https://connect.idcflare.com',
        'user_url': 'https://idcflare.com/u',
        'cf_cookies_file': "cf_cookies_idcflare.json",
        'session_file': "session_data_idcflare.json"
    }
]

# ç¯å¢ƒé…ç½®
BROWSE_ENABLED = os.environ.get("BROWSE_ENABLED", "true").strip().lower() not in ["false", "0", "off"]
HEADLESS = os.environ.get("HEADLESS", "true").strip().lower() not in ["false", "0", "off"]
FORCE_LOGIN_EVERY_TIME = os.environ.get("FORCE_LOGIN", "false").strip().lower() in ["true", "1", "on"]
BEHAVIOR_INJECTION_ENABLED = os.environ.get("BEHAVIOR_INJECTION_ENABLED", "true").strip().lower() not in ["false", "0", "off"]
AUTO_LIKE = os.environ.get("AUTO_LIKE", "true").strip().lower() not in ["false", "0", "off"]
OCR_API_KEY = os.getenv("OCR_API_KEY")
GITHUB_ACTIONS = os.environ.get("GITHUB_ACTIONS") == "true"

# ======================== ç¼“å­˜ç®¡ç†å™¨ ========================
class CacheManager:
    @staticmethod
    def get_cache_directory():
        return os.path.dirname(os.path.abspath(__file__))

    @staticmethod
    def get_cache_file_path(file_name):
        return os.path.join(CacheManager.get_cache_directory(), file_name)

    @staticmethod
    def load_cache(file_name):
        file_path = CacheManager.get_cache_file_path(file_name)
        if os.path.exists(file_path):
            try:
                with open(file_path, "r", encoding='utf-8') as f:
                    data = json.load(f)
                return data
            except Exception as e:
                try:
                    os.remove(file_path)
                except:
                    pass
        return None

    @staticmethod
    def save_cache(data, file_name):
        try:
            file_path = CacheManager.get_cache_file_path(file_name)
            with open(file_path, "w", encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜ä¿å­˜å¤±è´¥: {str(e)}")
            return False

    @staticmethod
    def load_site_cache(site_name, cache_type):
        file_name = f"{cache_type}_{site_name}.json"
        return CacheManager.load_cache(file_name)

    @staticmethod
    def save_site_cache(data, site_name, cache_type):
        file_name = f"{cache_type}_{site_name}.json"
        return CacheManager.save_cache(data, file_name)

    @staticmethod
    def clear_site_cache_on_failure(site_name):
        """ç™»å½•å¤±è´¥æ—¶æ¸…é™¤è¯¥ç«™ç‚¹çš„ç¼“å­˜"""
        try:
            cache_types = ['cf_cookies', 'session_data']
            for cache_type in cache_types:
                file_name = f"{cache_type}_{site_name}.json"
                file_path = CacheManager.get_cache_file_path(file_name)
                if os.path.exists(file_path):
                    os.remove(file_path)
            
            logger.info(f"âœ… {site_name} ç¼“å­˜å·²æ¸…é™¤")
            
        except Exception as e:
            logger.error(f"âŒ æ¸…é™¤ç¼“å­˜å¤±è´¥: {str(e)}")

# ======================== ä¸»æµè§ˆå™¨ç±» ========================
class LinuxDoBrowser:
    def __init__(self, site_config, credentials):
        self.site_config = site_config
        self.site_name = site_config['name']
        self.username = credentials['username']
        self.password = credentials['password']
        self.page = None
        self.browser = None
        self.cache_saved = False
        self.session_start_time = time.time()
        self.request_count = 0
        self.browsing_active = True
        self.initialize_browser()

    def initialize_browser(self):
        """æµè§ˆå™¨åˆå§‹åŒ– - ä¸“æ³¨åæ£€æµ‹"""
        try:
            co = ChromiumOptions()
            
            # GitHub Actions ç¯å¢ƒç‰¹æ®Šé…ç½®
            if GITHUB_ACTIONS:
                co.headless(True)
                co.set_argument("--no-sandbox")
                co.set_argument("--disable-dev-shm-usage")
                co.set_argument("--disable-gpu")
                co.set_argument("--disable-software-rasterizer")
            else:
                co.headless(HEADLESS)
                
            co.incognito(True)
            
            # åŸºç¡€åæ£€æµ‹é…ç½®
            co.set_argument("--disable-blink-features=AutomationControlled")
            co.set_argument("--disable-web-security")
            co.set_argument("--disable-features=TranslateUI")
            co.set_argument("--disable-background-networking")
            co.set_argument("--disable-sync")
            co.set_argument("--disable-translate")
            
            # ç”¨æˆ·ä»£ç†å’Œçª—å£è®¾ç½®
            user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            co.set_user_agent(user_agent)
            co.set_argument("--window-size=1920,1080")
        
            # ä¿å­˜browserå®ä¾‹
            self.browser = ChromiumPage(addr_or_opts=co)
            self.page = self.browser.new_tab()
            
            # æ‰§è¡ŒæŒ‡çº¹ä¼˜åŒ–
            self.enhance_browser_fingerprint()
            
            # åŠ è½½ä¼šè¯æ•°æ®
            self.session_data = CacheManager.load_site_cache(self.site_name, 'session_data') or {}
            
            logger.info("âœ… æµè§ˆå™¨åˆå§‹åŒ–æˆåŠŸ")
        
        except Exception as e:
            logger.error(f"âŒ æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise

    def enhance_browser_fingerprint(self):
        """æµè§ˆå™¨æŒ‡çº¹ä¼˜åŒ–"""
        try:
            js_code = """
            Object.defineProperties(navigator, {
                webdriver: { get: () => undefined },
                platform: { get: () => 'Win32' },
                hardwareConcurrency: { get: () => 8 },
                deviceMemory: { get: () => 8 },
                maxTouchPoints: { get: () => 0 }
            });

            Object.defineProperty(screen, 'width', {get: () => 1920});
            Object.defineProperty(screen, 'height', {get: () => 1080});
            """
            self.page.run_js(js_code)
        
        except Exception as e:
            logger.debug(f"æŒ‡çº¹ä¼˜åŒ–å¼‚å¸¸: {str(e)}")

    def smart_delay(self, min_time=2, max_time=5):
        """æ™ºèƒ½å»¶è¿Ÿ"""
        delay = random.uniform(min_time, max_time)
        time.sleep(delay)

    def handle_cloudflare_check(self, timeout=20):
        """å¤„ç†Cloudflareæ£€æŸ¥"""
        start_time = time.time()
        check_count = 0
        
        while time.time() - start_time < timeout:
            try:
                page_title = self.page.title
                check_count += 1
                
                if page_title and "Checking" not in page_title and "Just a moment" not in page_title:
                    body_length = len(self.page.html)
                    if body_length > 1000:
                        return True
                
                if page_title and ("Checking" in page_title or "Just a moment" in page_title):
                    logger.debug(f"Cloudflareæ£€æŸ¥ä¸­... ({check_count})")
                
                time.sleep(1)
                    
            except Exception as e:
                time.sleep(1)
        
        logger.warning(f"Cloudflareæ£€æŸ¥è¶…æ—¶ ({timeout}ç§’)ï¼Œç»§ç»­æ‰§è¡Œ")
        return True

    def save_caches(self):
        """ä¿å­˜ç¼“å­˜"""
        if self.cache_saved:
            return
            
        try:
            cookies = self.page.cookies()
            if cookies:
                CacheManager.save_site_cache(cookies, self.site_name, 'cf_cookies')
            
            session_data = {
                'last_success': datetime.now().isoformat(),
                'login_status': 'success',
                'last_updated': datetime.now().isoformat(),
                'site_name': self.site_name,
                'username_hash': hash(self.username) if self.username else 0,
                'total_runs': self.session_data.get('total_runs', 0) + 1
            }
            CacheManager.save_site_cache(session_data, self.site_name, 'session_data')
            
            self.cache_saved = True
            logger.info(f"âœ… {self.site_name} ç¼“å­˜ä¿å­˜å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜ä¿å­˜å¤±è´¥: {str(e)}")

    def try_cache_login(self):
        """å°è¯•ç¼“å­˜ç™»å½•"""
        if FORCE_LOGIN_EVERY_TIME:
            logger.info("âš ï¸ å¼ºåˆ¶é‡æ–°ç™»å½•")
            return False
            
        cookies = CacheManager.load_site_cache(self.site_name, 'cf_cookies')
        if not cookies:
            return False
        
        try:
            logger.info("ğŸ¯ å°è¯•ç¼“å­˜ç™»å½•...")
            self.page.get(self.site_config['base_url'])
            time.sleep(2)
            
            self.page.set.cookies(cookies)
            time.sleep(1)
            
            self.page.refresh()
            time.sleep(3)
            
            self.handle_cloudflare_check()
            
            if self.verify_login_status():
                logger.success("âœ… ç¼“å­˜ç™»å½•æˆåŠŸ")
                return True
            return False
                
        except Exception as e:
            logger.error(f"ç¼“å­˜ç™»å½•å¼‚å¸¸: {str(e)}")
            return False

    def verify_login_status(self, max_retries=3):
        """éªŒè¯ç™»å½•çŠ¶æ€"""
        logger.info("ğŸ” éªŒè¯ç™»å½•çŠ¶æ€...")
        
        for attempt in range(max_retries):
            try:
                private_url = self.site_config['private_topic_url']
                logger.info(f"ğŸ“ è®¿é—®ç§æœ‰ä¸»é¢˜ (å°è¯• {attempt+1}/{max_retries})")
                
                self.page.get(private_url)
                time.sleep(5)
                
                self.handle_cloudflare_check()
                time.sleep(3)
                
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸè®¿é—®ç§æœ‰ä¸»é¢˜
                content = self.page.html
                if "topic" in content.lower() or len(content) > 500000:
                    logger.success("ğŸ‰ ç™»å½•éªŒè¯é€šè¿‡")
                    return True
                
                time.sleep(2)
                
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.warning(f"éªŒè¯å°è¯• {attempt+1} å¼‚å¸¸ï¼Œé‡è¯•ä¸­...")
                    time.sleep(3)
        
        logger.error(f"âŒ ç™»å½•éªŒè¯å¤±è´¥")
        return False

    def login(self, max_retries=2):
        """ç™»å½•æµç¨‹"""
        self.page.set.cookies([])
        
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ” æ‰§è¡Œç™»å½• (å°è¯• {attempt+1}/{max_retries})")
                
                self.page.get(self.site_config['login_url'])
                time.sleep(3)
                
                self.page.wait.ele_displayed('#login-account-name', timeout=10)
                
                self.handle_cloudflare_check()
                time.sleep(1)
                
                # è¾“å…¥ç”¨æˆ·åå¯†ç 
                self.page.ele("#login-account-name").input(self.username)
                time.sleep(0.5)
                
                self.page.ele("#login-account-password").input(self.password)
                time.sleep(0.5)
                
                # ç‚¹å‡»ç™»å½•
                self.page.ele("#login-button").click()
                time.sleep(12)
                
                self.handle_cloudflare_check()
                time.sleep(3)
                
                if self.verify_login_status():
                    logger.success("âœ… ç™»å½•æˆåŠŸ")
                    self.save_caches()
                    return True
                else:
                    time.sleep(5)
                
            except Exception as e:
                logger.error(f"âŒ ç™»å½•å‡ºé”™ (å°è¯• {attempt+1}/{max_retries}): {str(e)}")
                if attempt < max_retries - 1:
                    time.sleep(5)
        
        logger.error("âŒ æ‰€æœ‰ç™»å½•å°è¯•å‡å¤±è´¥")
        return False

    def ensure_logged_in(self):
        """ç¡®ä¿ç™»å½•"""
        if not FORCE_LOGIN_EVERY_TIME and self.try_cache_login():
            return True
        
        login_success = self.login()
        if not login_success:
            CacheManager.clear_site_cache_on_failure(self.site_name)
        
        return login_success

    # ======================== æ ¸å¿ƒæµè§ˆæ–¹æ³•é‡æ„ ========================

    def inject_automation_script(self):
        """æ³¨å…¥è‡ªåŠ¨åŒ–è„šæœ¬ - å€Ÿé‰´å‚è€ƒä»£ç çš„æ ¸å¿ƒæœºåˆ¶"""
        try:
            js_code = """
            (function() {
                'use strict';
                
                // è®¾ç½®å…³é”®æ ‡è®° - ç¡®ä¿ç½‘ç«™çŸ¥é“è¿™æ˜¯çœŸå®ç”¨æˆ·
                localStorage.setItem('read', 'true');
                localStorage.setItem('isFirstRun', 'false');
                localStorage.setItem('autoLikeEnabled', '%s');
                
                // åˆ›å»ºå…¨å±€è¿½è¸ªå¯¹è±¡
                window.discourseReadingTracker = {
                    startTime: Date.now(),
                    scrollDepth: 0,
                    postRead: new Set(),
                    triggerEvent: function(eventName, data) {
                        const event = new CustomEvent(eventName, { 
                            detail: data,
                            bubbles: true,
                            cancelable: true
                        });
                        document.dispatchEvent(event);
                        
                        // åŒæ—¶è§¦å‘jQueryäº‹ä»¶ï¼ˆDiscourseä½¿ç”¨jQueryï¼‰
                        if (window.jQuery) {
                            jQuery(document).trigger(eventName, data);
                        }
                    }
                };
                
                // ç›‘å¬æ»šåŠ¨äº‹ä»¶æ¥è®°å½•é˜…è¯»è¡Œä¸º
                let lastScrollTime = 0;
                let scrollCount = 0;
                
                window.addEventListener('scroll', function() {
                    const now = Date.now();
                    if (now - lastScrollTime > 1000) {
                        scrollCount++;
                        lastScrollTime = now;
                        
                        // è®°å½•æ»šåŠ¨æ·±åº¦
                        const scrollDepth = (window.scrollY + window.innerHeight) / document.body.scrollHeight;
                        discourseReadingTracker.scrollDepth = Math.max(discourseReadingTracker.scrollDepth, scrollDepth);
                        
                        // è§¦å‘Discourseäº‹ä»¶
                        discourseReadingTracker.triggerEvent('discourse:user-activity', {
                            type: 'scrolling',
                            scrollDepth: scrollDepth,
                            timestamp: now
                        });
                        
                        // è§¦å‘é˜…è¯»è¿›åº¦äº‹ä»¶
                        const progress = Math.floor(scrollDepth * 4) / 4;
                        discourseReadingTracker.triggerEvent('discourse:reading-progress', {
                            progress: progress,
                            topicId: window.location.pathname.split('/').pop()
                        });
                    }
                });
                
                // å®šæœŸè§¦å‘æ´»åŠ¨äº‹ä»¶
                setInterval(function() {
                    // è§¦å‘Discourseçš„æ´»åŠ¨æ£€æµ‹
                    discourseReadingTracker.triggerEvent('discourse:user-activity', {
                        type: 'reading',
                        timestamp: Date.now()
                    });
                    
                    // è§¦å‘å¯è§æ€§å˜åŒ–
                    document.dispatchEvent(new Event('visibilitychange'));
                    
                    // è§¦å‘ç„¦ç‚¹äº‹ä»¶
                    window.dispatchEvent(new Event('focus'));
                }, 15000);
                
                // å¸–å­åŠ è½½äº‹ä»¶å¤„ç†
                function triggerPostEvents() {
                    const posts = document.querySelectorAll('.topic-post');
                    posts.forEach((post, index) => {
                        const postId = post.getAttribute('data-post-id');
                        if (postId && !discourseReadingTracker.postRead.has(postId)) {
                            discourseReadingTracker.postRead.add(postId);
                            
                            // è§¦å‘å¸–å­åŠ è½½äº‹ä»¶
                            discourseReadingTracker.triggerEvent('discourse:post-loaded', {
                                postId: postId,
                                index: index
                            });
                            
                            // è§¦å‘å¸–å­é˜…è¯»äº‹ä»¶
                            discourseReadingTracker.triggerEvent('discourse:post-read', {
                                postId: postId
                            });
                        }
                    });
                }
                
                // åˆå§‹è§¦å‘å¸–å­äº‹ä»¶
                setTimeout(triggerPostEvents, 1000);
                
                // ç›‘å¬DOMå˜åŒ–æ¥è§¦å‘æ–°å¸–å­äº‹ä»¶
                const observer = new MutationObserver(triggerPostEvents);
                observer.observe(document.body, { 
                    childList: true, 
                    subtree: true 
                });
                
                console.log('è‡ªåŠ¨åŒ–è„šæœ¬å·²æ³¨å…¥ - ç¡®ä¿æµè§ˆç—•è¿¹æ”¶é›†');
            })();
            """ % str(AUTO_LIKE).lower()
            
            self.page.run_js(js_code)
            return True
        except Exception as e:
            logger.error(f"âŒ è‡ªåŠ¨åŒ–è„šæœ¬æ³¨å…¥å¤±è´¥: {str(e)}")
            return False

    def ensure_script_injected(self):
        """ç¡®ä¿è„šæœ¬å·²æ³¨å…¥ - åŒé‡ä¿é™©"""
        try:
            # æ£€æŸ¥æ˜¯å¦å·²æ³¨å…¥
            injected = self.page.run_js("return !!window.discourseReadingTracker;")
            if not injected:
                return self.inject_automation_script()
            return True
        except:
            return self.inject_automation_script()

    def simulate_real_reading_behavior(self):
        """æ¨¡æ‹ŸçœŸå®é˜…è¯»è¡Œä¸º - å€Ÿé‰´å‚è€ƒä»£ç çš„100%æœ‰æ•ˆæœºåˆ¶"""
        try:
            logger.debug("ğŸ“– å¼€å§‹æ¨¡æ‹ŸçœŸå®é˜…è¯»è¡Œä¸º")
            
            # 1. åˆå§‹ç­‰å¾…è®©é¡µé¢å®Œå…¨åŠ è½½
            self.smart_delay(3, 6)
            
            # 2. ç¡®ä¿è„šæœ¬æ³¨å…¥
            self.ensure_script_injected()
            
            # 3. ä¸»å¸–æ·±åº¦é˜…è¯»
            logger.debug("ğŸ“ æ·±åº¦é˜…è¯»ä¸»å¸–å†…å®¹")
            self.deep_read_main_post()
            
            # 4. ç³»ç»ŸåŒ–æ»šåŠ¨æµè§ˆ
            logger.debug("ğŸ”„ ç³»ç»ŸåŒ–æ»šåŠ¨æµè§ˆ")
            self.systematic_scroll_browsing()
            
            # 5. è§¦å‘å®Œæˆäº‹ä»¶
            logger.debug("âœ… è§¦å‘é˜…è¯»å®Œæˆäº‹ä»¶")
            self.trigger_reading_completion()
            
            # 6. éšæœºç‚¹èµï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if AUTO_LIKE and random.random() < 0.1:  # 10%æ¦‚ç‡ç‚¹èµ
                self.click_like_button()
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ é˜…è¯»è¡Œä¸ºæ¨¡æ‹Ÿå¤±è´¥: {str(e)}")
            return False

    def deep_read_main_post(self):
        """æ·±åº¦é˜…è¯»ä¸»å¸– - ç¡®ä¿ä¸»å¸–è¢«å……åˆ†é˜…è¯»"""
        try:
            # æ»šåŠ¨åˆ°ä¸»å¸–å¼€å§‹ä½ç½®
            self.page.run_js("""
                const firstPost = document.querySelector('.topic-post:first-child');
                if (firstPost) {
                    firstPost.scrollIntoView({ behavior: 'smooth', block: 'start' });
                }
            """)
            self.smart_delay(2, 4)
            
            # åˆ†æ®µé˜…è¯»ä¸»å¸–å†…å®¹
            for i in range(4):
                scroll_amount = random.randint(200, 400)
                self.page.run_js(f"window.scrollBy(0, {scroll_amount});")
                
                # å…³é”®ï¼šåœ¨æ¯æ®µåœç•™è¶³å¤Ÿæ—¶é—´è®©ç½‘ç«™è®°å½•é˜…è¯»
                read_time = random.uniform(3, 6)
                time.sleep(read_time)
                
                # è§¦å‘é˜…è¯»äº‹ä»¶
                self.trigger_reading_events()
        
        except Exception as e:
            logger.debug(f"ä¸»å¸–é˜…è¯»å¼‚å¸¸: {e}")

    def systematic_scroll_browsing(self):
        """ç³»ç»ŸåŒ–æ»šåŠ¨æµè§ˆ - ç¡®ä¿æ•´ä¸ªé¡µé¢è¢«é˜…è¯»"""
        try:
            # è·å–é¡µé¢æ€»é«˜åº¦
            total_height = self.page.run_js("return document.body.scrollHeight;") or 3000
            
            # åˆ†æ®µæ»šåŠ¨ç­–ç•¥
            scroll_positions = [0.2, 0.4, 0.6, 0.8, 1.0]
            
            for position in scroll_positions:
                target_scroll = total_height * position
                
                # å¹³æ»‘æ»šåŠ¨åˆ°ç›®æ ‡ä½ç½®
                self.page.run_js(f"""
                    window.scrollTo({{
                        top: {target_scroll},
                        behavior: 'smooth'
                    }});
                """)
                
                # å…³é”®åœç•™ - è®©ç½‘ç«™è®°å½•é˜…è¯»è¡Œä¸º
                stay_time = random.uniform(4, 8)
                time.sleep(stay_time)
                
                # è§¦å‘è¯¥ä½ç½®çš„é˜…è¯»äº‹ä»¶
                self.trigger_position_events(position)
                
                # å¶å°”éšæœºæ»šåŠ¨æ¨¡æ‹ŸçœŸå®ç”¨æˆ·
                if random.random() < 0.3:
                    self.random_micro_scroll()
        
        except Exception as e:
            logger.debug(f"æ»šåŠ¨æµè§ˆå¼‚å¸¸: {e}")

    def trigger_reading_events(self):
        """è§¦å‘é˜…è¯»ç›¸å…³äº‹ä»¶"""
        try:
            self.page.run_js("""
                // è§¦å‘åŸºç¡€äº‹ä»¶
                document.dispatchEvent(new Event('visibilitychange'));
                window.dispatchEvent(new Event('focus'));
                window.dispatchEvent(new Event('scroll'));
                
                // è§¦å‘é¼ æ ‡ç§»åŠ¨
                document.dispatchEvent(new MouseEvent('mousemove', {
                    bubbles: true,
                    clientX: Math.random() * window.innerWidth,
                    clientY: Math.random() * window.innerHeight
                }));
            """)
        except:
            pass

    def trigger_position_events(self, position):
        """è§¦å‘ä½ç½®ç›¸å…³äº‹ä»¶"""
        try:
            self.page.run_js(f"""
                if (window.discourseReadingTracker) {{
                    // è§¦å‘é˜…è¯»è¿›åº¦äº‹ä»¶
                    discourseReadingTracker.triggerEvent('discourse:reading-progress', {{
                        progress: {position},
                        topicId: window.location.pathname.split('/').pop()
                    }});
                    
                    // è§¦å‘ç”¨æˆ·æ´»åŠ¨äº‹ä»¶
                    discourseReadingTracker.triggerEvent('discourse:user-activity', {{
                        type: 'position_change',
                        position: {position},
                        timestamp: Date.now()
                    }});
                }}
            """)
        except:
            pass

    def random_micro_scroll(self):
        """éšæœºå¾®æ»šåŠ¨"""
        try:
            scroll_amount = random.randint(-100, 100)
            self.page.run_js(f"window.scrollBy(0, {scroll_amount});")
            time.sleep(random.uniform(1, 2))
        except:
            pass

    def trigger_reading_completion(self):
        """è§¦å‘é˜…è¯»å®Œæˆäº‹ä»¶"""
        try:
            self.page.run_js("""
                // æ»šåŠ¨åˆ°åº•éƒ¨ç¡®è®¤å®Œæˆ
                window.scrollTo(0, document.body.scrollHeight);
                
                // è§¦å‘å®Œæˆäº‹ä»¶
                if (window.discourseReadingTracker) {
                    const topicId = window.location.pathname.split('/').pop();
                    const readingTime = Math.floor((Date.now() - window.discourseReadingTracker.startTime) / 1000);
                    
                    discourseReadingTracker.triggerEvent('discourse:reading-complete', {
                        topicId: topicId,
                        readingTime: readingTime,
                        scrollDepth: window.discourseReadingTracker.scrollDepth,
                        postsRead: Array.from(window.discourseReadingTracker.postRead)
                    });
                    
                    // è®¾ç½®å®Œæˆæ ‡è®°
                    localStorage.setItem(`discourse-topic-${topicId}-read`, 'true');
                    localStorage.setItem(`discourse-topic-${topicId}-read-time`, new Date().toISOString());
                }
                
                console.log('é˜…è¯»å®Œæˆäº‹ä»¶å·²è§¦å‘');
            """)
            
            # æœ€ç»ˆåœç•™ç¡®ä¿äº‹ä»¶å¤„ç†å®Œæˆ
            time.sleep(random.uniform(3, 6))
            
        except Exception as e:
            logger.debug(f"å®Œæˆäº‹ä»¶è§¦å‘å¼‚å¸¸: {e}")

    def click_like_button(self):
        """ç‚¹å‡»ç‚¹èµæŒ‰é’®"""
        try:
            like_button = self.page.ele('.discourse-reactions-reaction-button')
            if like_button:
                logger.info("ğŸ‘ å°è¯•ç‚¹èµ...")
                like_button.click()
                time.sleep(random.uniform(1, 2))
                logger.success("âœ… ç‚¹èµæˆåŠŸ")
                return True
            return False
        except Exception as e:
            logger.debug(f"ç‚¹èµå¤±è´¥: {e}")
            return False

    def find_topic_elements(self):
        """æŸ¥æ‰¾ä¸»é¢˜å…ƒç´ """
        logger.info("ğŸ¯ æŸ¥æ‰¾ä¸»é¢˜...")
        
        try:
            self.page.wait.doc_loaded()
            time.sleep(3)
            
            all_links = self.page.eles('tag:a', timeout=10)
            if not all_links:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•é“¾æ¥")
                return []
            
            seen_ids = set()
            topic_urls = []
            
            for link in all_links:
                href = link.attr('href')
                if not href:
                    continue
                
                # æ’é™¤éä¸»é¢˜é“¾æ¥
                if any(exclude in href.lower() for exclude in ['/tags/', '/c/', '/u/', '/uploads/', '.png', '.jpg', '.gif']):
                    continue
                
                # æå–ä¸»é¢˜ID
                match = re.search(r'/t/(?:topic/)?(\d+)', href)
                if match:
                    topic_id = match.group(1)
                    if topic_id not in seen_ids:
                        seen_ids.add(topic_id)
                        full_url = f"{self.site_config['base_url'].rstrip('/')}/t/topic/{topic_id}"
                        topic_urls.append(full_url)
            
            logger.info(f"ğŸ”— æ‰¾åˆ° {len(topic_urls)} ä¸ªä¸»é¢˜")
            return topic_urls
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥æ‰¾ä¸»é¢˜å¤±è´¥: {str(e)}")
            return []

    def browse_topics_guaranteed(self):
        """ä¿è¯æµè§ˆç—•è¿¹æ”¶é›†çš„ä¸»é¢˜æµè§ˆ"""
        if not BROWSE_ENABLED:
            logger.info("â­ï¸ æµè§ˆåŠŸèƒ½å·²ç¦ç”¨")
            return 0

        try:
            logger.info(f"ğŸŒ å¼€å§‹ä¿è¯æµè§ˆç—•è¿¹æ”¶é›†çš„ {self.site_name} ä¸»é¢˜æµè§ˆ...")
            
            # è·å–ä¸»é¢˜åˆ—è¡¨
            self.page.get(self.site_config['unread_url'])
            time.sleep(3)
            
            topic_urls = self.find_topic_elements()
            if not topic_urls:
                logger.warning("âŒ æœªæ‰¾åˆ°å¯æµè§ˆçš„ä¸»é¢˜")
                return 0
            
            # é€‰æ‹©é€‚é‡ä¸»é¢˜è¿›è¡Œæ·±åº¦æµè§ˆ
            browse_count = min(random.randint(3, 6), len(topic_urls))
            selected_urls = random.sample(topic_urls, browse_count)
            success_count = 0
            
            logger.info(f"ğŸ“Š è®¡åˆ’æ·±åº¦æµè§ˆ {browse_count} ä¸ªä¸»é¢˜")
            
            for i, topic_url in enumerate(selected_urls):
                try:
                    logger.info(f"ğŸ“– æ·±åº¦æµè§ˆä¸»é¢˜ {i+1}/{browse_count}")
                    
                    # è®¿é—®ä¸»é¢˜é¡µé¢
                    self.page.get(topic_url)
                    time.sleep(2)
                    
                    # æ‰§è¡Œä¿è¯æµè§ˆç—•è¿¹çš„é˜…è¯»è¡Œä¸º
                    if self.simulate_real_reading_behavior():
                        success_count += 1
                        logger.success(f"âœ… ä¸»é¢˜ {i+1} æµè§ˆå®Œæˆ")
                    else:
                        logger.warning(f"âš ï¸ ä¸»é¢˜ {i+1} æµè§ˆå¼‚å¸¸")
                    
                    # è¿”å›åˆ—è¡¨é¡µ
                    self.page.get(self.site_config['unread_url'])
                    time.sleep(2)
                    
                    # ä¸»é¢˜é—´ç­‰å¾…
                    if i < browse_count - 1:
                        interval = random.uniform(5, 10)
                        logger.info(f"â³ ä¸»é¢˜é—´ç­‰å¾… {interval:.1f} ç§’...")
                        time.sleep(interval)
                        
                except Exception as e:
                    logger.error(f"âŒ æµè§ˆä¸»é¢˜å¤±è´¥: {str(e)}")
                    continue
            
            logger.success(f"ğŸ‰ å…±æˆåŠŸæ·±åº¦æµè§ˆ {success_count} ä¸ªä¸»é¢˜")
            return success_count
            
        except Exception as e:
            logger.error(f"âŒ ä¸»é¢˜æµè§ˆå¤±è´¥: {str(e)}")
            return 0

    def get_connect_info_single_tab(self):
        """è·å–è¿æ¥ä¿¡æ¯"""
        logger.info("ğŸ”— è·å–è¿æ¥ä¿¡æ¯...")
        
        try:
            current_url = self.page.url
            
            # è®¿é—®è¿æ¥é¡µé¢
            self.page.get(self.site_config['connect_url'])
            time.sleep(5)
            
            # ç­‰å¾…è¡¨æ ¼å‡ºç°
            table = None
            for i in range(5):
                table = self.page.ele("tag:table", timeout=5)
                if table:
                    break
                time.sleep(2)
            
            if not table:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°è¿æ¥ä¿¡æ¯è¡¨æ ¼")
                if self.site_name == 'idcflare':
                    logger.info("â„¹ï¸ idcflareè¿æ¥ä¿¡æ¯è·å–å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹")
                self.page.get(current_url)
                time.sleep(2)
                return True
            
            # è§£æè¡¨æ ¼æ•°æ®
            rows = table.eles("tag:tr")
            info = []
            
            for row in rows:
                cells = row.eles("tag:td")
                if len(cells) >= 3:
                    project = cells[0].text.strip()
                    current = cells[1].text.strip()
                    requirement = cells[2].text.strip()
                    if project and current and requirement:
                        info.append([project, current, requirement])
            
            if info:
                print("\n" + "="*60)
                print(f"ğŸ“Š {self.site_name.upper()} è¿æ¥ä¿¡æ¯")
                print("="*60)
                print(tabulate(info, headers=["é¡¹ç›®", "å½“å‰", "è¦æ±‚"], tablefmt="pretty"))
                print("="*60 + "\n", flush=True)
                
                passed = sum(1 for item in info if any(indicator in str(item[1]) for indicator in ['âœ…', 'âœ”', 'âœ“', 'â‰¥', '%']))
                total = len(info)
                logger.success(f"ğŸ“ˆ ç»Ÿè®¡: {passed}/{total} é¡¹è¾¾æ ‡")
            else:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°è¿æ¥ä¿¡æ¯æ•°æ®")
            
            # è¿”å›åŸé¡µé¢
            self.page.get(current_url)
            time.sleep(2)
            
            logger.info("âœ… è¿æ¥ä¿¡æ¯è·å–å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ è·å–è¿æ¥ä¿¡æ¯å¤±è´¥: {str(e)}")
            if self.site_name == 'idcflare':
                logger.info("â„¹ï¸ idcflareè¿æ¥ä¿¡æ¯å¼‚å¸¸ï¼Œä½†ä¸å½±å“ç»§ç»­æ‰§è¡Œ")
                return True
            try:
                self.page.get(self.site_config['unread_url'])
                time.sleep(2)
            except:
                pass
            return False

    def run_complete_process(self):
        """æ‰§è¡Œå®Œæ•´æµç¨‹"""
        try:
            logger.info(f"ğŸš€ å¼€å§‹å¤„ç† {self.site_name}")
            
            # 1. ç¡®ä¿ç™»å½•
            if not self.ensure_logged_in():
                logger.error(f"âŒ {self.site_name} ç™»å½•å¤±è´¥")
                return False
                                
            # 2. è¿æ¥ä¿¡æ¯
            connect_success = self.get_connect_info_single_tab()
            if not connect_success and self.site_name != 'idcflare':
                logger.warning(f"âš ï¸ {self.site_name} è¿æ¥ä¿¡æ¯è·å–å¤±è´¥")

            # 3. ä½¿ç”¨ä¿è¯æµè§ˆç—•è¿¹çš„ä¸»é¢˜æµè§ˆæ–¹æ³•
            browse_count = self.browse_topics_guaranteed()
            
            # 4. ä¿å­˜ç¼“å­˜
            self.save_caches()
            
            logger.success(f"âœ… {self.site_name} å¤„ç†å®Œæˆ - æ·±åº¦æµè§ˆ {browse_count} ä¸ªä¸»é¢˜")
            return True
            
        except Exception as e:
            logger.error(f"âŒ {self.site_name} æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            return False
            
        finally:
            self.browsing_active = False
            try:
                if self.browser:
                    self.browser.quit()
            except:
                pass

# ======================== ä¸»å‡½æ•° ========================
def main():
    logger.info("ğŸš€ Linux.Do è‡ªåŠ¨åŒ– v6.0 é‡æ„ç‰ˆå¯åŠ¨")
    
    if GITHUB_ACTIONS:
        logger.info("ğŸ¯ GitHub Actions ç¯å¢ƒ")
    
    success_sites = []
    failed_sites = []

    # æ£€æŸ¥å‡­è¯
    for site_name, creds in SITE_CREDENTIALS.items():
        if not creds.get('username') or not creds.get('password'):
            logger.warning(f"â­ï¸ {site_name} å‡­è¯æœªé…ç½®")

    # ç«™ç‚¹é€‰æ‹©
    site_selector = os.environ.get("SITE_SELECTOR", "all")
    target_sites = SITES if site_selector == "all" else [s for s in SITES if s['name'] == site_selector]

    if not target_sites:
        logger.error(f"âŒ æœªæ‰¾åˆ°ç«™ç‚¹: {site_selector}")
        sys.exit(1)

    logger.info(f"ğŸ¯ ç›®æ ‡ç«™ç‚¹: {', '.join([s['name'] for s in target_sites])}")

    for site_config in target_sites:
        site_name = site_config['name']
        credentials = SITE_CREDENTIALS.get(site_name, {})

        if not credentials.get('username') or not credentials.get('password'):
            logger.warning(f"â­ï¸ è·³è¿‡ {site_name} - å‡­è¯æœªé…ç½®")
            failed_sites.append(site_name)
            continue

        logger.info(f"ğŸ”§ å¤„ç†ç«™ç‚¹: {site_name}")
        
        try:
            browser = LinuxDoBrowser(site_config, credentials)
            success = browser.run_complete_process()

            if success:
                success_sites.append(site_name)
            else:
                failed_sites.append(site_name)
                
        except Exception as e:
            logger.error(f"âŒ {site_name} æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            failed_sites.append(site_name)

        # ç«™ç‚¹é—´ç­‰å¾…
        if site_config != target_sites[-1]:
            wait_time = random.uniform(10, 20)
            logger.info(f"â³ ç«™ç‚¹é—´ç­‰å¾… {wait_time:.1f} ç§’...")
            time.sleep(wait_time)

    # æ€»ç»“
    logger.info("=" * 60)
    logger.info("ğŸ“Š æ‰§è¡Œæ€»ç»“:")
    logger.info(f"âœ… æˆåŠŸ: {', '.join(success_sites) if success_sites else 'æ— '}")
    logger.info(f"âŒ å¤±è´¥: {', '.join(failed_sites) if failed_sites else 'æ— '}")
    logger.info("=" * 60)

    if success_sites:
        logger.success(f"ğŸ‰ ä»»åŠ¡å®Œæˆ: {len(success_sites)}/{len(target_sites)} ä¸ªç«™ç‚¹æˆåŠŸ")
        sys.exit(0)
    else:
        logger.error("ğŸ’¥ ä»»åŠ¡å¤±è´¥: æ‰€æœ‰ç«™ç‚¹å‡æœªæˆåŠŸ")
        sys.exit(1)

if __name__ == "__main__":
    required_vars = ['LINUXDO_USERNAME', 'LINUXDO_PASSWORD']
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    
    if missing_vars:
        logger.warning(f"âš ï¸ å¿…éœ€ç¯å¢ƒå˜é‡æœªè®¾ç½®: {', '.join(missing_vars)}")
    
    if not OCR_API_KEY:
        logger.warning("âš ï¸ æœªé…ç½®OCR_API_KEYï¼ŒéªŒè¯ç å¤„ç†å°†ä¸å¯ç”¨")
    
    main()

